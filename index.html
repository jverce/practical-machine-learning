<h2 id="introduction">Introduction</h2>

<p>The purpose of this document is to describe the process of creating a machine learning model to predict the class of exercise from certain motion variables. The original experiment is called <strong>Human Activity Recognition</strong> and more information can be found here: <a href="http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har">http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har</a></p>

<p>The experiment basically took place by adding several motion detectors in different parts of the human body and recording their output during specific gym routines. These routines where performed by different subjects and in a supervised way. The main goal of the original experiment is to determine which exercise a user is performing and whether or not it's properly performing it.</p>

<p>In our case we'll be using the training data acquired in the original experiment and try to build a machine learning model that predicts the class of exercise being performed based on the motion variables.</p>

<h2 id="datacleanup">Data Cleanup</h2>

<p>In this section we'll be performing a data cleanup since the original files contain a lot of undefined information that can negatively impact our analysis.</p>

<h3 id="loaddata">Load Data</h3>

<p>We start by loading both the training and testing data and storing it in the <code>training</code> and <code>testing</code> variables, respectively:</p>

<pre><code class=" r language- r">training &lt;- read.csv('./pml-training.csv')
testing &lt;- read.csv('./pml-testing.csv')
</code></pre>

<h3 id="glimpse">Glimpse</h3>

<p>We take a quick glimpse at our data to find some inconsistent/improper variables to discard. <em>Keep in mind that we're hiding the results from this report since it's too verbose, but they're still reproducible</em>.</p>

<pre><code class=" r language- r">head(training)
</code></pre>

<pre><code class=" r language- r">summary(training)
</code></pre>

<p>Based on the output we can find the following variables to remove:</p>

<ul>
<li><code>X</code>: it's a variable that indicates the record number and should definitely be removed prior to our analysis</li>

<li><code>user_name</code>: similar to the previous variable, the user name should not be used as a predictor for a general case.</li>

<li><code>new_window</code>: this variable presents inconsistencies in its values and it's better to leave it out.</li>

<li>Timestamp variables: these are variables that contain <code>timestamp</code> in their name. They do not provide information about the subject's movement and so they shouldn't affect our prediction.</li>

<li><code>NA</code> variables: these variables have undefined values and since we don't have any way to supply them we have no option but to remove them.</li>

<li><code>#DIV/0!</code> variables: looks like variables that experienced some strange issue during their recording and we can't rely on their values, hence we'll be removing them.</li>
</ul>

<h3 id="variableremoval">Variable Removal</h3>

<p>As per the previous section, we proceed to remove the mentioned variables:</p>

<pre><code class=" r language- r"># Remove `X` var
training &lt;- subset(training, select = -c(X))

# Remove `user_name` var
training &lt;- subset(training, select = -c(user_name))

# Remove `new_window` var
training &lt;- subset(training, select = -c(new_window))

# Remove timestamp vars
training &lt;- subset(training, select = -grep('timestamp', colnames(training)))

# Remove `NA` and `#DIV/0!` vars
for (col in names(training)) {
  nas &lt;- sum(is.na(training[, col])) &gt; 0
  div0 &lt;- any(grep("DIV/0", training[, col]))
  if (nas || div0) {
    training &lt;- subset(training, select=(!names(training) %in% c(col)))
  }
}
</code></pre>

<p>Finally we see how many variables are left in our training set:</p>

<pre><code class=" r language- r">dim(training)
</code></pre>

<pre><code>## [1] 19622    54
</code></pre>

<h2 id="buildmodel">Build Model</h2>

<p>To build our machine learning model we'll be using the <em>random forest</em> algorithm since it provides a fair amount of accuracy. The only aspect we need to be aware of is the possibility of overfitting. We can play around with the <code>mtry</code> variable in order to balance between the accuracy against the training set and the amount of variables sampled as candidates: we can reduce overfitting and simplifying the model at the same time by reducing the <code>mtry</code> value we provide as input.</p>

<p>We try with the following <code>mtry</code> values:</p>

<ul>
<li>2 (minimum)</li>

<li>27 (half the max)</li>

<li>54 (maximum)</li>
</ul>

<pre><code class=" r language- r">library(randomForest)
</code></pre>

<pre><code>## randomForest 4.6-12

## Type rfNews() to see new features/changes/bug fixes.
</code></pre>

<pre><code class=" r language- r">randomForest(classe ~ ., data = training, mtry = 2)
</code></pre>

<pre><code>##
## Call:
##  randomForest(formula = classe ~ ., data = training, mtry = 2)
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
##
##         OOB estimate of  error rate: 0.28%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 5579    1    0    0    0 0.0001792115
## B    6 3790    1    0    0 0.0018435607
## C    0   13 3409    0    0 0.0037989480
## D    0    0   28 3187    1 0.0090174129
## E    0    0    0    4 3603 0.0011089548
</code></pre>

<pre><code class=" r language- r">randomForest(classe ~ ., data = training, mtry = 27)
</code></pre>

<pre><code>##
## Call:
##  randomForest(formula = classe ~ ., data = training, mtry = 27)
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
##
##         OOB estimate of  error rate: 0.15%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 5578    1    0    0    1 0.0003584229
## B    4 3790    3    0    0 0.0018435607
## C    0    5 3416    1    0 0.0017533606
## D    0    0    8 3207    1 0.0027985075
## E    0    0    0    5 3602 0.0013861935
</code></pre>

<pre><code class=" r language- r">randomForest(classe ~ ., data = training, mtry = 54)
</code></pre>

<pre><code>## Warning in randomForest.default(m, y, ...): invalid mtry: reset to within
## valid range

##
## Call:
##  randomForest(formula = classe ~ ., data = training, mtry = 54)
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 53
##
##         OOB estimate of  error rate: 0.29%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 5576    2    1    0    1 0.0007168459
## B   17 3774    5    1    0 0.0060574137
## C    0    6 3413    3    0 0.0026300409
## D    0    1   13 3201    1 0.0046641791
## E    0    1    0    5 3601 0.0016634322
</code></pre>

<p>We can see that the best performance is achieved with <code>mtry = 27</code>. Since the value is below the max number we're basically discarding variables which reduces the chance of overfitting.</p>

<p>We can now do a prediction to check if the output looks consistent:</p>

<pre><code class=" r language- r">library(caret)
</code></pre>

<pre><code>## Loading required package: lattice

## Loading required package: ggplot2

##
## Attaching package: 'ggplot2'

## The following object is masked from 'package:randomForest':
##
##     margin

## Warning in as.POSIXlt.POSIXct(Sys.time()): unknown timezone 'zone/tz/2017c.
## 1.0/zoneinfo/America/Vancouver'
</code></pre>

<pre><code class=" r language- r">fit &lt;- randomForest(classe ~ ., data = training, mtry = 27)
predict(fit, testing)
</code></pre>

<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B
## Levels: A B C D E
</code></pre>

<p>As per the <strong>final quiz</strong>, the result is 100% accurate.</p>

<h2 id="conclusions">Conclusions</h2>

<p>As seen before, it is very important to perform a data inspection prior to any analysis since there might be dummy, dirty or auxiliary variables that are not consistent with the processing and information we need to extract.</p>

<p>We observed that by applying the random forest algorithm we were able to obtain a prediction model that is accurate enough without overfitting the initial training data. Even though we used the <code>mtry</code> parameter to balance the precision and complexity of the model, there are other parameters that can be adapted as well (check the official <code>randomForest</code> <a href="https://cran.r-project.org/web/packages/randomForest/randomForest.pdf">documentation</a> for more information).</p>

<p>Finally we used the obtained model to perform a prediction on the tesing dataset with 100% accuracy according to the final quiz of the course.</p>
